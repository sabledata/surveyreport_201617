---
title: "Summary of the annual 2016 and 2017 sablefish (*Anoplopoma fimbria*) trap surveys, October 7 - November 22, 2016 and October 6 - November 21, 2017"
year: 2016
report_number: 3396
author: |
  Lisa C. Lacko, 
  Schon M. Acheson and
  Kendra Holt
author_list: "Lacko, L.C., Acheson, S.M. and Kendra Holt"
region: Pacific Region
isbn: "978-0-660-35792-8"
address: |
     Pacific Biological Station\
     Fisheries and Oceans Canada, 3190 Hammond Bay Road\
     Nanaimo, British Columbia, V9T 6N7, Canada\
phone: "(250) 756-7000"
author_footnote: "Email: Lisa.Lacko@dfo-mpo.gc.ca | telephone: (250) 756-7385"
abstract: |
  This document describes sampling activities and summarizes results from the 2016 and 2017 British Columbia sablefish research and assessment surveys. These annual surveys utilized the same sampling strategies at stratified random (StRS) sites and traditional inlet sites. The random component was comprised of StRS sets at five depth-stratified areas and the traditional component employed standardized sets at four inlet localities on the mainland.  In total,  sablefish were caught in 2016, of which  were used for biological samples and  were tagged and released. In 2017, a total of  sablefish were caught, of which  were used for biological samples and  were tagged and released. 
  
  Catch per unit effort (CPUE) is an important result from this survey as it is used to infer population trends. In most recent years, survey data from StRS sets show increasing trends in both mean weight and numbers of fish per trap. CPUE at traditional inlet sites have varied in a predictable manner over time with peak CPUE occurring every 5-8 years and increasing to record levels in 2016 and 2017. At both StRS and traditional inlet sites, the average weight of sablefish in 2016 and 2017 reached record mean lows due to large numbers of small fish.

abstract_other: |
  Le présent document décrit les activités d’échantillonnage et résume les résultats des relevés de recherche et d’évaluation de la morue charbonnière menées en Colombie-Britannique en 2018 et 2019. Ces relevés annuels utilisaient les mêmes stratégies d’échantillonnage aux sites aléatoires stratifiés et aux sites traditionnels des bras de mer. La composante aléatoire était composée d’ensembles de sites aléatoires stratifiés dans cinq zones stratifiées en fonction de la profondeur, tandis que la composante traditionnelle était composée d’ensembles normalisés à quatre bras de mer continentaux.  Au total, 58 415 morues charbonnières ont été capturées en 2018, dont 5 741 ont servi à prélever des échantillons biologiques et 10 965 ont été marquées et remises à l’eau. En 2019, un total de 78 836 morues charbonnières ont été capturées, dont 5 659 ont se9rvi à prélever des échantillons biologiques et 12 042 ont été marquées et remises à l’eau.

  Les captures par unité d’effort (CPUE) sont un important résultat de ce relevé; elles sont utilisées pour déduire les tendances démographiques. Au cours des dernières années, les données tirées des relevés pour les ensembles aux sites aléatoires stratifiés démontrent des tendances à la hausse en ce qui a trait au poids moyen et au nombre de poissons par casier. Les CPUE aux sites traditionnels des bras de mer varient de façon prévisible au fil du temps et atteignent un sommet tous les 5 à 8 ans; elles ont atteint des sommets records en 2018 et 2019. Aux sites aléatoires stratifiés et aux sites traditionnels, le poids moyen des morues charbonnières en 2018 et 2019 a atteint un creux record en raison du grand nombre de petits poissons.

output:
 csasdown::techreport_pdf:
   french: false
type:
  techreport
# ------------
# End of options to set
knit: bookdown::render_book
site: bookdown::bookdown_site
link-citations: true
bibliography: bib/refs.bib
csl: csl/csas.csl
lot: true
lof: true
# Any extra LaTeX code for the header:
# header-includes:
# - \usepackage{tikz}
header-includes: \usepackage{pdflscape}
                 
---

```{r setup, echo=FALSE, cache=FALSE, message=FALSE, results='hide', warning=FALSE}
library(knitr)
if (is_latex_output()) {
  knitr_figs_dir  <- "knitr-figs-pdf/"
  knitr_cache_dir <- "knitr-cache-pdf/"
  fig_out_type    <- "png"
} else {
  knitr_figs_dir  <- "knitr-figs-docx/"
  knitr_cache_dir <- "knitr-cache-docx/"
  fig_out_type    <- "png"
}
fig_asp   <- 0.618
fig_width <- 9
fig_out_width <- "6in"
fig_dpi   <- 180
fig_align <- "center"
fig_pos   <- "htb"
opts_chunk$set(
  collapse = TRUE,
  warning = FALSE,
  message = FALSE,
  comment = "#>",
  fig.path = knitr_figs_dir,
  cache.path = knitr_cache_dir,
  fig.asp = fig_asp,
  fig.width = fig_width,
  out.width = fig_out_width,
  echo = FALSE,
  #  autodep = TRUE,
  #  cache = TRUE,
  cache.comments = FALSE,
  dev = fig_out_type,
  dpi = fig_dpi,
  fig.align = fig_align,
  fig.pos = fig_pos
)
options(xtable.comment = FALSE)
options(kableExtra.latex.load_packages = FALSE)
```

```{r load-libraries, cache=FALSE}
# add other packages here:
library(csasdown)
message("year = ", rmarkdown::metadata$year)
#browser()
yr  <-  2016
basepath <- 'c:/github/surveyreport_201617/'
path     <- 'c:/github/surveyreport_201617/standaloneData/'

library(RODBC)
library(knitr)
library(magick)
library(excelR)
library(gapminder)
library(ggplot2)
library(dplyr)        # transform and summarize tabular data
library(xtable)       # produces tables
library(kableExtra)   # produces html tables with scrollbars, etc
library(pacman)       # produces numbered tables and figures in order to reference them
 #  if (!require("pacman")) install.packages("pacman")
 #  pacman::p_load(knitr, captioner, bundesligR, stringr)
library(bookdown)
library(tableHTML)
library(Rmisc)
library(cowplot)
#  ----   G L O B A L --- F U N C T I O N S ---------------------------------
  GetSQLData <- function(strSQL,strDbName) {    # connect to SQL Server
         cnn <- odbcDriverConnect(paste("Driver={SQL Server};Server=DFBCV9TWVASP001;", 
                                         "Database=",
                                          strDbName,";
                                          Trusted_Connection=Yes",
                                          sep=""))
            dat <- sqlQuery(cnn, strSQL)
            odbcClose(cnn)
            return(dat) 
                                            }
  
  panLab <- function( x, y, txt, ... ) { # Allows text to be placed at 0<x<1, 0<y<1)
            usr <- par( "usr" )
            par( usr=c(0,1,0,1) )
            text( x, y, txt, ... )
            par( usr=usr )
            #return( NULL )
            }
  
  cleanf <- function(x){                            # function to remove duplicates
            oldx <- c(FALSE, x[-1]==x[-length(x)])  # is value equal to previous value
            res <- x
            res[oldx] <- NA
            return(res)
            } 
  
  simpleCap <- function(x) {  # add capital first letter to each word
            s <- strsplit(x, " ")[[1]]
            paste(toupper(substring(s, 1,1)), substring(s, 2),
            sep="", 
            collapse=" ")
            }
  
  firstup <- function(x) {   # add capital first letter to first word
            substr(x, 1, 1) <- toupper(substr(x, 1, 1))
            x
  }
  
  format_cells <- function(df, rows ,cols, value = c("italics", "bold", "strikethrough")){
            # select the correct markup
            map    <- setNames(c("*", "**", "~~"), c("italics", "bold", "strikethrough"))
            markup <- map[value]  
            
            for (r in rows){
                  for(c in cols){
                      df[[c]] <- as.character( df[[c]])  # -- make sure values not factors
                      df[r, c] <- paste0(markup, df[r, c], markup)  # -- Update formatting
                                }
                           }
                     return(df)
            }
            
  fig_label <- function(text, region="figure", pos="topleft", cex=NULL, ...) {
           
            region <- match.arg(region, c("figure", "plot", "device"))
            pos    <- match.arg(pos,    c("topleft",    "top", "topright", 
                                          "left",       "center", "right", 
                                          "bottomleft", "bottom", "bottomright"))
           
            if(region %in% c("figure", "device")) {
              ds <- dev.size("in")
              # xy coordinates of device corners in user coordinates
              x <- grconvertX(c(0, ds[1]), from="in", to="user")
              y <- grconvertY(c(0, ds[2]), from="in", to="user")
           
              # fragment of the device we use to plot
              if(region == "figure") {
                # account for the fragment of the device that 
                # the figure is using
                fig <- par("fig")
                dx <- (x[2] - x[1])
                dy <- (y[2] - y[1])
                x <- x[1] + dx * fig[1:2]
                y <- y[1] + dy * fig[3:4]
              } 
            }
           
            # much simpler if in plotting region
            if(region == "plot") {
              u <- par("usr")
              x <- u[1:2]
              y <- u[3:4]
            }
           
            sw <- strwidth(text, cex=cex) * 60/100
            sh <- strheight(text, cex=cex) * 60/100
           
            x1 <- switch(pos,
              topleft     =x[1] + sw, 
              left        =x[1] + sw,
              bottomleft  =x[1] + sw,
              top         =(x[1] + x[2])/2,
              center      =(x[1] + x[2])/2,
              bottom      =(x[1] + x[2])/2,
              topright    =x[2] - sw,
              right       =x[2] - sw,
              bottomright =x[2] - sw)
           
            y1 <- switch(pos,
              topleft     =y[2] - sh,
              top         =y[2] - sh,
              topright    =y[2] - sh,
              left        =(y[1] + y[2])/2,
              center      =(y[1] + y[2])/2,
              right       =(y[1] + y[2])/2,
              bottomleft  =y[1] + sh,
              bottom      =y[1] + sh,
              bottomright =y[1] + sh)
           
            old.par <- par(xpd=NA)
            on.exit(par(old.par))
           
            text(x1, y1, text, cex=cex, ...)
            return(invisible(c(x,y)))
}
  
```

```{r, echo=FALSE}
   inline_hook <- function(x) {  # -- for inline text where numbers are larger 
      if (is.numeric(x)) {
            format(x, digits = 2)
                         } else x
      }
   knitr::knit_hooks$set(inline = inline_hook)
```

```{r SurveyDetails, echo=FALSE} 
   yr <- 2016
   # -- GLOBAL DETAILS FROM SQL SERVER QUERIES/STAND ALONE CSV FILES--
   details     <- paste("select VESSEL_NAME as Vessel, CAPTAIN, ",
                        "LEFT(CONVERT(varchar, START_DATE, 100), 7) + ' - ' ",
                        "+ LEFT(CONVERT(varchar, END_DATE, 100), 7) AS [Trip Dates], ",
                        "COUNT([SET]) AS [Count of Sets] ",
                        "from  dbo.GFBIO_RESEARCH_TRIPS ",
                        "where year IN( ", yr ,",", yr + 1 ,") ", 
                        "group by ",
                        "VESSEL_NAME, CAPTAIN,  ",
                        "LEFT(CONVERT(varchar, START_DATE, 100),7) + ' - ' + ",
                        "LEFT(CONVERT(varchar, END_DATE, 100),7)", 
                         sep="")
   survey.details <- GetSQLData(details,"Sablefish")  # -- survey details query SQL Server
   write.table(survey.details, file = paste(path,"index01.csv",sep=''),row.names=FALSE, na="",col.names=TRUE,  sep=",")
   survey.details <- read.csv(paste(path,'index01.csv',sep=''), header=T)
   
   boat1       <- simpleCap(tolower(survey.details[1,1]))      # -- vessel name year 1
   boat2       <- simpleCap(tolower(survey.details[2,1]))      # -- vessel name year 2
   
   captain1    <- simpleCap(tolower(survey.details[1,2]))      # -- captain name year 1
   captain2    <- simpleCap(tolower(survey.details[2,2]))      # -- captain name year 2
   captain2    <- "Albert (Deacon) Melnychuk"                  # -- unique to 2017
   
   dates1      <- survey.details[1,3]           # -- survey start and end dates year 1
   dates2      <- survey.details[2,3]           # -- survey start and end dates year 2
   
   set.count1  <- survey.details[1,4]           # -- survey set count year 1
   set.count2  <- survey.details[2,4]           # -- survey set count year 2
   
   avgC        <- paste("select ROUND(AVG(TOTAL), 0) AS YrAvg ",
                        "from   dbo.TableA2_Annual_sablefish_Landing_in_Can_waters_2 ",
                        "where (year <= ", yr+1, ") and (year >= ",yr - 8,")", sep="")
   #avgTen      <- GetSQLData(avgC,"Sablefish")                # -- average catch last 10 years query SQL Server 
   #write.table(avgTen, file = paste(path,"index02.csv",sep=''), row.names=FALSE, na="",col.names=TRUE,  sep=",")
   avgTen      <- read.csv(paste(path,'index02.csv',sep=''), header=T)

   tp          <- paste("select  ROUND(TRAP / TOTAL * 100, 0) AS TrapPer ",
                        "from    dbo.TableA2_Annual_sablefish_Landing_in_Can_waters_2 ",  
                        "where  (year = ", yr, ")  group by ROUND(TRAP / TOTAL * 100, 0), TOTAL", sep="")
   trapP      <- GetSQLData(tp,"Sablefish")                     # -- trap gear catch ratio year 1
   write.table(trapP, file = paste(path,"index03.csv",sep=''), row.names=FALSE, na="",col.names=TRUE,  sep=",")
   trapP      <- read.csv(paste(path,'index03.csv',sep=''), header=T)
   
   lp          <- paste("select  ROUND(LONGLINE / TOTAL * 100, 0) AS LonglinePer ",  
                         "from   dbo.TableA2_Annual_sablefish_Landing_in_Can_waters_2  ",
                         "where  (year = ", yr, ") group by ROUND(LONGLINE / TOTAL * 100, 0), TOTAL", sep="")
   LonglineP  <- GetSQLData(lp,"Sablefish")                     # -- longline gear catch ratio year 1
   write.table(LonglineP, file = paste(path,"index04.csv",sep=''), row.names=FALSE, na="",col.names=TRUE,  sep=",")
   LonglineP   <- read.csv(paste(path,'index04.csv',sep=''), header=T)
   
   tp2         <- paste("select  ROUND(TRAP / TOTAL * 100, 0) AS TrapPer ",
                        "from    dbo.TableA2_Annual_sablefish_Landing_in_Can_waters_2 ",  
                        "where  (year = ", yr + 1, ")  group by ROUND(TRAP / TOTAL * 100, 0), TOTAL", sep="")
   trapP2     <- GetSQLData(tp2,"Sablefish")                     # -- trap gear catch ratio year 2
   write.table(trapP2, file = paste(path,"index05.csv",sep=''), row.names=FALSE, na="",col.names=TRUE,  sep=",")
   trapP2      <- read.csv(paste(path,'index05.csv',sep=''), header=T)
   
   lp2         <-  paste("select  ROUND(LONGLINE / TOTAL * 100, 0) AS LonglinePer  ",  
                         "from    dbo.TableA2_Annual_sablefish_Landing_in_Can_waters_2  ",
                         "where  (year = ", yr + 1, ") group by ROUND(LONGLINE / TOTAL * 100, 0), TOTAL", sep="")
   LonglineP2 <- GetSQLData(lp2,"Sablefish")                     # -- longline gear catch ratio  year 2
   write.table(LonglineP2, file = paste(path,"index06.csv",sep=''), row.names=FALSE, na="",col.names=TRUE,  sep=",")
   LonglineP2  <- read.csv(paste(path,'index06.csv',sep=''), header=T)
   
   # -- F I G U R E   C A P T I O N S  function ------------------------------------------------
   figure_nums <-  captioner::captioner(prefix = "Figure")
   fg.ref      <-  function(x) {    # another method on how to number figures
                                     stringr::str_extract(figure_nums(x), "[^.]*")}
   
```